{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001B[0m\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                320       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,610\n",
      "Trainable params: 4,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas\\Desktop\\books\\django\\environment\\lib\\site-packages\\gym\\envs\\registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.policy import EpsGreedyQPolicy\n",
    "\n",
    "# Set up the environment\n",
    "env_name = 'CartPole-v1'\n",
    "env = gym.make(env_name)\n",
    "num_actions = env.action_space.n\n",
    "\n",
    "# Define the Q-network architecture\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(4,), activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_actions, activation='linear')\n",
    "])\n",
    "print(model.summary())\n",
    "# Set up the DQN agent\n",
    "memory = SequentialMemory(limit=10000, window_length=1)\n",
    "policy = EpsGreedyQPolicy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas\\Desktop\\books\\django\\environment\\lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "dqn_agent = DQNAgent(\n",
    "    model=model,\n",
    "    nb_actions=num_actions,\n",
    "    memory=memory,\n",
    "    nb_steps_warmup=10,\n",
    "    target_model_update=1e-2,\n",
    "    policy=policy\n",
    ")\n",
    "dqn_agent.compile(optimizer=Adam(lr=1e-3), metrics=['mae'])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10000 steps ...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_input to have 2 dimensions, but got array with shape (1, 1, 4)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Train the agent\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mdqn_agent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnb_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvisualize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Evaluate the agent\u001B[39;00m\n\u001B[0;32m      5\u001B[0m dqn_agent\u001B[38;5;241m.\u001B[39mtest(env, nb_episodes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, visualize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\Desktop\\books\\django\\environment\\lib\\site-packages\\rl\\core.py:168\u001B[0m, in \u001B[0;36mAgent.fit\u001B[1;34m(self, env, nb_steps, action_repetition, callbacks, verbose, visualize, nb_max_start_steps, start_step_policy, log_interval, nb_max_episode_steps)\u001B[0m\n\u001B[0;32m    165\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mon_step_begin(episode_step)\n\u001B[0;32m    166\u001B[0m \u001B[38;5;66;03m# This is were all of the work happens. We first perceive and compute the action\u001B[39;00m\n\u001B[0;32m    167\u001B[0m \u001B[38;5;66;03m# (forward step) and then use the reward to improve (backward step).\u001B[39;00m\n\u001B[1;32m--> 168\u001B[0m action \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobservation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    169\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocessor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    170\u001B[0m     action \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocessor\u001B[38;5;241m.\u001B[39mprocess_action(action)\n",
      "File \u001B[1;32m~\\Desktop\\books\\django\\environment\\lib\\site-packages\\rl\\agents\\dqn.py:224\u001B[0m, in \u001B[0;36mDQNAgent.forward\u001B[1;34m(self, observation)\u001B[0m\n\u001B[0;32m    221\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, observation):\n\u001B[0;32m    222\u001B[0m     \u001B[38;5;66;03m# Select an action.\u001B[39;00m\n\u001B[0;32m    223\u001B[0m     state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmemory\u001B[38;5;241m.\u001B[39mget_recent_state(observation)\n\u001B[1;32m--> 224\u001B[0m     q_values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_q_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    225\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining:\n\u001B[0;32m    226\u001B[0m         action \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpolicy\u001B[38;5;241m.\u001B[39mselect_action(q_values\u001B[38;5;241m=\u001B[39mq_values)\n",
      "File \u001B[1;32m~\\Desktop\\books\\django\\environment\\lib\\site-packages\\rl\\agents\\dqn.py:68\u001B[0m, in \u001B[0;36mAbstractDQNAgent.compute_q_values\u001B[1;34m(self, state)\u001B[0m\n\u001B[0;32m     67\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_q_values\u001B[39m(\u001B[38;5;28mself\u001B[39m, state):\n\u001B[1;32m---> 68\u001B[0m     q_values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_batch_q_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mflatten()\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m q_values\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m==\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnb_actions,)\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m q_values\n",
      "File \u001B[1;32m~\\Desktop\\books\\django\\environment\\lib\\site-packages\\rl\\agents\\dqn.py:63\u001B[0m, in \u001B[0;36mAbstractDQNAgent.compute_batch_q_values\u001B[1;34m(self, state_batch)\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_batch_q_values\u001B[39m(\u001B[38;5;28mself\u001B[39m, state_batch):\n\u001B[0;32m     62\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_state_batch(state_batch)\n\u001B[1;32m---> 63\u001B[0m     q_values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_on_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     64\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m q_values\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m==\u001B[39m (\u001B[38;5;28mlen\u001B[39m(state_batch), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnb_actions)\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m q_values\n",
      "File \u001B[1;32m~\\Desktop\\books\\django\\environment\\lib\\site-packages\\keras\\engine\\training_v1.py:1305\u001B[0m, in \u001B[0;36mModel.predict_on_batch\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m   1300\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[0;32m   1301\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`predict_on_batch` is not supported for models distributed \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1302\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwith tf.distribute.Strategy.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1303\u001B[0m     )\n\u001B[0;32m   1304\u001B[0m \u001B[38;5;66;03m# Validate and standardize user data.\u001B[39;00m\n\u001B[1;32m-> 1305\u001B[0m inputs, _, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_standardize_user_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1306\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextract_tensors_from_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[0;32m   1307\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1308\u001B[0m \u001B[38;5;66;03m# If `self._distribution_strategy` is True, then we are in a replica\u001B[39;00m\n\u001B[0;32m   1309\u001B[0m \u001B[38;5;66;03m# context at this point.\u001B[39;00m\n\u001B[0;32m   1310\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_eagerly \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_distribution_strategy:\n",
      "File \u001B[1;32m~\\Desktop\\books\\django\\environment\\lib\\site-packages\\keras\\engine\\training_v1.py:2652\u001B[0m, in \u001B[0;36mModel._standardize_user_data\u001B[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001B[0m\n\u001B[0;32m   2643\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   2644\u001B[0m     \u001B[38;5;129;01mnot\u001B[39;00m run_eagerly\n\u001B[0;32m   2645\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m is_build_called\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2648\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(_is_symbolic_tensor(v) \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m all_inputs)\n\u001B[0;32m   2649\u001B[0m ):\n\u001B[0;32m   2650\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [], [], \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 2652\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_standardize_tensors\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2653\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2654\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2655\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2656\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrun_eagerly\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_eagerly\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2657\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdict_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdict_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2658\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2659\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2660\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2661\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\books\\django\\environment\\lib\\site-packages\\keras\\engine\\training_v1.py:2693\u001B[0m, in \u001B[0;36mModel._standardize_tensors\u001B[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001B[0m\n\u001B[0;32m   2690\u001B[0m \u001B[38;5;66;03m# Standardize the inputs.\u001B[39;00m\n\u001B[0;32m   2691\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, (tf\u001B[38;5;241m.\u001B[39mcompat\u001B[38;5;241m.\u001B[39mv1\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataset, tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataset)):\n\u001B[0;32m   2692\u001B[0m     \u001B[38;5;66;03m# TODO(fchollet): run static checks with dataset output shape(s).\u001B[39;00m\n\u001B[1;32m-> 2693\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mtraining_utils_v1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstandardize_input_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2694\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2695\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfeed_input_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2696\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfeed_input_shapes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2697\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_batch_axis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Don't enforce the batch size.\u001B[39;49;00m\n\u001B[0;32m   2698\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexception_prefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minput\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2699\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2701\u001B[0m \u001B[38;5;66;03m# Get typespecs for the input data and sanitize it if necessary.\u001B[39;00m\n\u001B[0;32m   2702\u001B[0m \u001B[38;5;66;03m# TODO(momernick): This should be capable of doing full input validation\u001B[39;00m\n\u001B[0;32m   2703\u001B[0m \u001B[38;5;66;03m# at all times - validate that this is so and refactor the\u001B[39;00m\n\u001B[0;32m   2704\u001B[0m \u001B[38;5;66;03m# standardization code.\u001B[39;00m\n\u001B[0;32m   2705\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataset):\n",
      "File \u001B[1;32m~\\Desktop\\books\\django\\environment\\lib\\site-packages\\keras\\engine\\training_utils_v1.py:712\u001B[0m, in \u001B[0;36mstandardize_input_data\u001B[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001B[0m\n\u001B[0;32m    710\u001B[0m shape \u001B[38;5;241m=\u001B[39m shapes[i]\n\u001B[0;32m    711\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data_shape) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(shape):\n\u001B[1;32m--> 712\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    713\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError when checking \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    714\u001B[0m         \u001B[38;5;241m+\u001B[39m exception_prefix\n\u001B[0;32m    715\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m: expected \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    716\u001B[0m         \u001B[38;5;241m+\u001B[39m names[i]\n\u001B[0;32m    717\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m to have \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    718\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mlen\u001B[39m(shape))\n\u001B[0;32m    719\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m dimensions, but got array with shape \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    720\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(data_shape)\n\u001B[0;32m    721\u001B[0m     )\n\u001B[0;32m    722\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m check_batch_axis:\n\u001B[0;32m    723\u001B[0m     data_shape \u001B[38;5;241m=\u001B[39m data_shape[\u001B[38;5;241m1\u001B[39m:]\n",
      "\u001B[1;31mValueError\u001B[0m: Error when checking input: expected dense_input to have 2 dimensions, but got array with shape (1, 1, 4)"
     ]
    }
   ],
   "source": [
    "# Train the agent\n",
    "dqn_agent.fit(env, nb_steps=10000, visualize=False, verbose=2)\n",
    "\n",
    "# Evaluate the agent\n",
    "dqn_agent.test(env, nb_episodes=5, visualize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}